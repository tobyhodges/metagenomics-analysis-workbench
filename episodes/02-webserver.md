---
title: "Metagenomic Cloud Services"
teaching: 5
exercises: 15
questions:
- "What are cloud services?"
- "How can I analyze metagenomic data with them?"
objectives:
- "Explore our data in a metagenomic web server."
- "Log into a remote machine through command line."
- "Understand the differences between local and web servers."  
keypoints:
- "There are web services for metagenomic analysis, like MG-RAST."
- "AWS is a computer cloud instance that can be used to do metagenomic analyzes."
- "Web services are easy to use, but cannot be tweaked as much."
- "AWS and local computers allow a greater degree of personalization."

---

## Cloud pipelines can be web or command-line based
The cloud is that place where we can send our data to be stored and analyzed. 
To access cloud services, we can use traditional web pages (think of Dropbox or Google Drive), or 
use a more direct connection through the command line. In this lesson we explore both approaches
to upload, store and analyze our metagenomic data.

For the web bounded cloud services we will use MG-RAST, an online metagenomic plataform where 
you can upload your raw data with its corresponding metadata and get a full taxonomic analysis of
it. MG-RAST is a great place to get started in this type of analyzes and it is also a big repository of 
available data for future experiments. On the downside, it is not possible to greatly modifiy the steps 
and parameters in the MG-RAST workflow, so there is not much leeway when it comes to implement our 
prefered analysis tools when using MG-RAST.

On the other hand, we have the other type of cloud services, like AWS. These, in contrast to 
web-bound services like MG-RAST, are much more flexibe, since they are basically powerful computers 
to which we access remotely. The downside here is that we access these cloud services 
through the command line, so there is practically no graphical interface, which can be a little bit 
jarring if you're not used to work through text commands alone. 

In short, command line workflows are more flexible and adaptable to individual needs, 
but automated web servers can quickly and easly give us a idea of the content of our data. 
So easly and quickly that, in fact, our Cuatro Ciénegas data is already in MG-RAST! 
You can check it out [here](https://www.mg-rast.org/mgmain.html?mgpage=project&project=mgp96823). 

## Cuatro Ciénegas in MG-RAST  

Let's check the taxonomical distribution of our sample first. If you look at the MG-RAST charts, 
we can see that our Cuatro Ciénegas sample is mostly bacteria.  

<a href="{{ page.root }}/fig/03-01-03.png">
  <img src="{{ page.root }}/fig/03-01-03.png" alt="Domain" />
</a>


The most abundant phylum is Proteobacteria.  
<a href="{{ page.root }}/fig/03-01-04.png">
  <img src="{{ page.root }}/fig/03-01-04.png" alt="Phylum" />
</a>

 And going even further, we can see that the most abundant genera is *Erythrobacter*. 
 <a href="{{ page.root }}/fig/03-01-05.png">
  <img src="{{ page.root }}/fig/03-01-05.png" alt="Genus" />
</a>

Since we have a shotgun metagenome, we can also investigate the metabolic functions 
present in our sample. MG-RAST can find genes and annotate their function through 
an implementation of RAST, or Rapid Annotation using Subsystems Technology. 
By looking at the charts generated by this analysis, we see that most of the genes
are dedicated to metabolism.  

<a href="{{ page.root }}/fig/03-01-06.png">
  <img src="{{ page.root }}/fig/03-01-06.png" alt="Cog Metagenome" />
</a>

<a href="{{ page.root }}/fig/03-01-07.png">
  <img src="{{ page.root }}/fig/03-01-07.png" alt="Subsystems" />
</a>

 <a href="{{ page.root }}/fig/03-01-08.png">
  <img src="{{ page.root }}/fig/03-01-08.png" alt="Predicted features" />
</a>
 
<a href="{{ page.root }}/fig/03-01-09.png">
  <img src="{{ page.root }}/fig/03-01-09.png" alt="Source Hits" />
</a>

> ## Exercise 1: Searching for information in MG-RAST  
> 
> We saw the piecharts for kingdom, phylum and genera, but what about family?. Which family is the most abundant?
> 
> 
>> ## Solution
>>  The piechart from MG-RAST shows that *Rhodobacteraceae* is the most abundant family. 
>> 
> {: .solution}
{: .challenge}


## AWS is a command-line cloud server 
The cloud computer we are going to use is provided by Amazon Web Services (AWS). It is already equiped with 
all of the metagenomic analysis command-line utilities needed fot this workshop. To use it, we have to open our terminal
(it should be accesible in any Linux distribution and OSX10; for Windows, you can install gitBash). Find your terminal 
and then type the commands to log into the service and move files between your remote and your local computer.  


~~~
$ ssh dcuser@ec2-3-238-253-45.compute-1.amazonaws.com 
~~~
{: .bash} 

~~~
Welcome to Ubuntu 14.04.3 LTS (GNU/Linux 3.13.0-48-generic x86_64)                                                                                                     * 
Documentation:  https://help.ubuntu.com/                                                                                                                             
System information as of Fri Nov 27 06:29:17 UTC 2020 
~~~
{: .output}

We need to know where are we located in the AWS machine, to know the direction 
of the files that we are going to copy between the AWS machine and your local machine. 
To do this, we can check the current directory with `pwd`.
~~~
$ pwd 
~~~
{: .bash}  
~~~
$ /home/dcuser  
~~~
{: .output}

We are inside a directory called dcuser, which is, itself, insde the home directory.

As we have learned, to copy files between your computer and the remote computer, we will use the `scp` command.  
Remeber that this must be done in a terminal that has your local computer open, not the remote computer. The general syntax to use `scp` would be like this: 
~~~
$ scp <where is the file> <where do you want the file to be>  
~~~
{: .output}  

Let's copy the metadata file `MGRAST_MetaData_JP.xlsx` from your remote machine to your local one. 
The file's at `/home/dcuser/dc_workshop/metadata/`, and our current directory can be represented by a dot, so to
copy this file _from_ our remote machine _into_ our local machine wee have to do the following: 

~~~
$ scp dcuser@ec2-3-238-253-45.compute-1.amazonaws.com:/home/dcuser/dc_workshop/metadata/MGRAST_MetaData_JP.xlsx .
~~~
{: .bash}  

~~~
MGRAST_MetaData_JP.xlsx                          100%   53KB 164.8KB/s   00:00  
~~~
{: .output}  


> ## Exercise 2: Copying files to remote machine
> 
> We want to send the file `APJ4_MetaData_JP.xlsx` to your remote computer. How can we do it? 
>
>   a) ssh dcuser@ec2-3-238-253-45.compute-1.amazonaws.com:/home/dcuser/. APJ4_MetaData_JP.xlsx  
>
>   b) ssh APJ4_MetaData_JP.xlsx dcuser@ec2-3-238-253-45.compute-1.amazonaws.com:/home/dcuser/.  
>
>   c) scp APJ4_MetaData_JP.xlsx dcuser@ec2-3-238-253-45.compute-1.amazonaws.com:/home/dcuser/.  
>
>> ## Solution  
>> ~~~ 
>> $  scp APJ4_MetaData_JP.xlsx dcuser@ec2-3-238-253-45.compute-1.amazonaws.com:/home/dcuser/.
>> ~~~
>> {: .bash}
>> ~~~ 
>> c option is the only one that uses secure copy command.   
>> ~~~
>> {: .output}
> {: .solution}
{: .challenge}

Now we put everything that we've learned into use.
Let's download a fasta file in your AWS remote computer called `JP4D.fasta` in the `dc_workshop/assembly/` directory.
You can sign up for an MG-RAST account and try to upload this file. 

> ## Exercise 3: Downloading a file to local machine
> How can you download the file?   
>> ## Solution
>> ~~~
>>  scp dcuser@ec2-3-238-253-45.compute-1.amazonaws.com:/home/dcuser/dc_workshop/assembly/JP4D.fasta .
>> ~~~
>> {: .bash}
>>
> {: .solution}
{: .challenge}

> ## Discussion
> Should we upload just the `JP4D.fasta` to MG-RAST?   
{: .discussion}
